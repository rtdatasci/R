#   date_sighted >= input$dates[1],
#   date_sighted <= input$dates[2]
# ) %>%
leaflet() %>%
addTiles() %>%
addMarkers(~longitude,
~latitude,
popup = ~as.character(usa_ufo_sightings$shape))
runApp('rtdatasci_github/R/alienz/alien_app.R')
traceback()
gc()
library(shiny)
library(dplyr)
library(ggplot2)
library(DT)
library(leaflet)
## global
# Data downloaded from: https://www.kaggle.com/datasets/NUFORC/ufo-sightings
usa_ufo_sightings <- read.csv("~/rtdatasci_github/R/alienz/scrubbed.csv")
## Pre-processing and cleanup
# remove rows with no state data (to keep US only data for this case)
usa_ufo_sightings <- usa_ufo_sightings %>%
filter(!is.na(state)) %>%
filter(state != "") %>%
mutate(state = toupper(state)) %>%
# format colname for ease of use
dplyr::rename(duration_sec = 'duration..seconds.') %>%
# convert to numeric for metrics
mutate(duration_sec = as.numeric(duration_sec),
latitude = as.numeric(latitude),
longitude = as.numeric(longitude)) %>%
# Remove rows with non-numeric duration_sec and latitude
filter(is.numeric(duration_sec)) %>%
filter(is.numeric(latitude)) %>%
# Remove rows with missing latitude longitude
filter(!is.na(latitude)) %>%
filter(!is.na(longitude)) %>%
# create date only column
usa_ufo_sightings <- usa_ufo_sightings %>%
mutate(date_sighted = str_extract(datetime, "^[^\\s]+")) %>%
# format date
mutate(date_sighted = as.character(as.Date(date_sighted, "%m/%d/%Y")))
usa_ufo_sightings <- usa_ufo_sightings %>%
filter(!is.na(state)) %>%
filter(state != "") %>%
mutate(state = toupper(state))
usa_ufo_sightings <- read.csv("~/rtdatasci_github/R/alienz/scrubbed.csv")
## Pre-processing and cleanup
# remove rows with no state data (to keep US only data for this case)
usa_ufo_sightings <- usa_ufo_sightings %>%
filter(!is.na(state)) %>%
filter(state != "") %>%
mutate(state = toupper(state)) %>%
# format colname for ease of use
dplyr::rename(duration_sec = 'duration..seconds.')
usa_ufo_sightings <- read.csv("~/rtdatasci_github/R/alienz/scrubbed.csv")
## Pre-processing and cleanup
# remove rows with no state data (to keep US only data for this case)
usa_ufo_sightings <- usa_ufo_sightings %>%
filter(!is.na(state)) %>%
filter(state != "") %>%
mutate(state = toupper(state)) %>%
# format colname for ease of use
dplyr::rename(duration_sec = 'duration..seconds.') %>%
# convert to numeric for metrics
mutate(duration_sec = as.numeric(duration_sec),
latitude = as.numeric(latitude),
longitude = as.numeric(longitude))
usa_ufo_sightings <- read.csv("~/rtdatasci_github/R/alienz/scrubbed.csv")
## Pre-processing and cleanup
# remove rows with no state data (to keep US only data for this case)
usa_ufo_sightings <- usa_ufo_sightings %>%
filter(!is.na(state)) %>%
filter(state != "") %>%
mutate(state = toupper(state)) %>%
# format colname for ease of use
dplyr::rename(duration_sec = 'duration..seconds.') %>%
# convert to numeric for metrics
mutate(duration_sec = as.numeric(duration_sec),
latitude = as.numeric(latitude),
longitude = as.numeric(longitude)) %>%
# Remove rows with non-numeric duration_sec and latitude
filter(is.numeric(duration_sec)) %>%
filter(is.numeric(latitude))
## global
# Data downloaded from: https://www.kaggle.com/datasets/NUFORC/ufo-sightings
usa_ufo_sightings <- read.csv("~/rtdatasci_github/R/alienz/scrubbed.csv")
## Pre-processing and cleanup
# remove rows with no state data (to keep US only data for this case)
usa_ufo_sightings <- usa_ufo_sightings %>%
filter(!is.na(state)) %>%
filter(state != "") %>%
mutate(state = toupper(state)) %>%
# format colname for ease of use
dplyr::rename(duration_sec = 'duration..seconds.') %>%
# convert to numeric for metrics
mutate(duration_sec = as.numeric(duration_sec),
latitude = as.numeric(latitude),
longitude = as.numeric(longitude)) %>%
# Remove rows with non-numeric duration_sec and latitude
filter(is.numeric(duration_sec)) %>%
filter(is.numeric(latitude)) %>%
# Remove rows with missing latitude longitude
filter(!is.na(latitude)) %>%
filter(!is.na(longitude))
# create date only column
usa_ufo_sightings <- usa_ufo_sightings %>%
mutate(date_sighted = str_extract(datetime, "^[^\\s]+")) %>%
# format date
mutate(date_sighted = as.character(as.Date(date_sighted, "%m/%d/%Y")))
# check data min and max dates
min(usa_ufo_sightings$date_sighted)
max(usa_ufo_sightings$date_sighted)
ui <- fluidPage(
titlePanel("UFO Sightings"),
sidebarPanel(
selectInput("state", "Choose a U.S. state:", choices = unique(usa_ufo_sightings$state)),
dateRangeInput("dates", "Choose a date range:",
start = "1920-01-01",
end = "1950-01-01"
)
),
# MODIFY CODE BELOW: Create a tab layout for the dashboard
mainPanel(
tabsetPanel(
tabPanel("MAP", leafletOutput("map")),
tabPanel('SHAPES',plotOutput("shapes")),
tabPanel('DURATION', tableOutput("duration_table")
)
)
)
)
server <- function(input, output) {
output$map <- renderLeaflet({
usa_ufo_sightings %>%
filter(
state == input$state,
date_sighted >= input$dates[1],
date_sighted <= input$dates[2]
) %>%
leaflet() %>%
addTiles() %>%
addMarkers(lng =  ~longitude,
lat =  ~latitude,
popup = ~as.character(usa_ufo_sightings$shape))
})
output$shapes <- renderPlot({
usa_ufo_sightings %>%
filter(
state == input$state,
date_sighted >= input$dates[1],
date_sighted <= input$dates[2]
) %>%
ggplot(aes(shape)) +
geom_bar() +
labs(
x = "Shape",
y = "# Sighted"
)
})
output$duration_table <- renderTable({
usa_ufo_sightings %>%
filter(
state == input$state,
date_sighted >= input$dates[1],
date_sighted <= input$dates[2]
) %>%
group_by(shape) %>%
summarize(
nb_sighted = n(),
avg_duration_min = mean(duration_sec) / 60,
median_duration_min = median(duration_sec) / 60,
min_duration_min = min(duration_sec) / 60,
max_duration_min = max(duration_sec) / 60
)
})
}
shinyApp(ui, server)
data <- read.csv("~/rtdatasci_github/R/mental_health_in_tech/mental-heath-in-tech-2016_20161114.csv")
View(data)
library(shiny)
library(ggplot2)
library(dplyr)
library(DT)
install.packages("shinyWidgets")
library(shinyWidgets)
install.packages("haven")
library(shiny); runApp('rtdatasci_github/bmi_app.R')
runApp('rtdatasci_github/bmi_app.R')
library(shiny)
# global
bmi_help_text <- "Body Mass Index is a simple calculation using a person's height and weight. The formula is BMI = kg/m2 where kg is a person's weight in kilograms and m2 is their height in metres squared. A BMI of 25.0 or more is overweight, while the healthy range is 18.5 to 24.9."
ui <- fluidPage(
titlePanel('BMI Calculator'),
sidebarLayout(
sidebarPanel(
textInput('name', 'Enter your name'),
numericInput('height', 'Enter your height in meters', 1.5, 1, 2),
numericInput('weight', 'Enter your weight in Kilograms', 60, 45, 120),
actionButton("show_bmi", "Show BMI"),
# CODE BELOW: Add an action button named "show_help"
actionButton("show_help", "Show Help")
),
mainPanel(
textOutput("bmi")
)
)
)
server <- function(input, output, session) {
# MODIFY CODE BELOW: Wrap in observeEvent() so the help text
# is displayed when a user clicks on the Help button.
observeEvent(input$show_help,{
# Display a modal dialog with bmi_help_text
# MODIFY CODE BELOW: Uncomment code
showModal(modalDialog(bmi_help_text))
})
rv_bmi <- eventReactive(input$show_bmi, {
input$weight/(input$height^2)
})
output$bmi <- renderText({
bmi <- rv_bmi()
paste("Hi", input$name, ". Your BMI is", round(bmi, 1))
})
}
shinyApp(ui = ui, server = server)
library(shiny)
# global
bmi_help_text <- "Body Mass Index is a simple calculation using a person's height and weight. The formula is BMI = kg/m2 where kg is a person's weight in kilograms and m2 is their height in metres squared. A BMI of 25.0 or more is overweight, while the healthy range is 18.5 to 24.9."
ui <- fluidPage(
titlePanel('BMI Calculator'),
sidebarLayout(
sidebarPanel(
textInput('name', 'Enter your name'),
numericInput('height', 'Enter your height in meters', 1.5, 1, 2),
numericInput('weight', 'Enter your weight in Kilograms', 60, 45, 120),
actionButton("show_bmi", "Show BMI"),
# action button named "show_help"
actionButton("show_help", "Show Help")
),
mainPanel(
textOutput("bmi")
)
)
)
server <- function(input, output, session) {
# Display when user clicks on the Help button.
observeEvent(input$show_help,{
# Display a modal dialog with bmi_help_text
showModal(modalDialog(bmi_help_text))
})
rv_bmi <- eventReactive(input$show_bmi, {
input$weight/(input$height^2)
})
output$bmi <- renderText({
bmi <- rv_bmi()
paste("Hi", input$name, ". Your BMI is", round(bmi, 1))
})
}
shinyApp(ui = ui, server = server)
runApp('rtdatasci_github/R/bmi_calculator')
runApp('rtdatasci_github/R/bmi_calculator/bmi_app.R')
install.packages("haven")
library(tidyverse)
Sys.setenv("AWS_DEFAULT_REGION" = 'us-west-2')
key <- "AKIAVP4JOWKTJJMQTUPW" # Substitute with your own (see below)
secret <- "95U1UAOUenvrbKPVUD/bBAN877cF8OK1z7Tg/ITi" # (see below)
Sys.setenv("AWS_ACCESS_KEY_ID" = key,
"AWS_SECRET_ACCESS_KEY" = secret)
bucketlist() # This returns a list of all your buckets if authentication was successful
library(aws.s3)
library(aws.ec2metadata)
key <- "AKIAVP4JOWKTJJMQTUPW" # Substitute with your own (see below)
secret <- "95U1UAOUenvrbKPVUD/bBAN877cF8OK1z7Tg/ITi" # (see below)
Sys.setenv("AWS_ACCESS_KEY_ID" = key,
"AWS_SECRET_ACCESS_KEY" = secret)
bucketlist() # This returns a list of all your buckets if authentication was successful
file_list <- aws.s3::get_bucket("s3://cupofaws/")  # s3 object lists
file_df <- aws.s3::get_bucket_df("s3://cupofaws/")  # s3 object dataframe
all_files <- file_df$Key
myfile <- s3read_using(FUN = read_excel, object = "test.xlsx", bucket = "cupofaws")
library(readxl)
myfile <- s3read_using(FUN = read_excel, object = "test.xlsx", bucket = "cupofaws")
myfile <- s3read_using(FUN = read_excel, object = "s3://cupofaws/test.xlsx")
all_files
myfile_mod <- myfile %>% mutate(new_col = ifelse(str_detect(col2, "[a-z]"), "alphanumeric", "numeric"))
s3write_using(myfile_mod, FUN = write_csv, object = "s3://cupofaws/test_mod.csv")
library(jsonlite)
# Load the JSON file
json_data <- fromJSON(file = "~/rtdatasci_github/R/aws/aws_key.json")
# Load the JSON file
json_data <- fromJSON(txt = "~/rtdatasci_github/R/aws/aws_key.json")
View(json_data)
# Retrieve the AWS key values
access_key_id <- json_data$AWS_ACCESS_KEY_ID
secret_access_key <- json_data$AWS_SECRET_ACCESS_KEY
key <- json_data$AWS_ACCESS_KEY_ID
secret <- json_data$AWS_SECRET_ACCESS_KEY
Sys.setenv("AWS_ACCESS_KEY_ID" = key,
"AWS_SECRET_ACCESS_KEY" = secret)
bucketlist() # This returns a list of all your buckets if authentication was successful
file_list <- aws.s3::get_bucket("s3://cupofaws/")  # s3 object lists
file_df <- aws.s3::get_bucket_df("s3://cupofaws/")  # s3 object dataframe
all_files <- file_df$Key
all_files
library(readxl)
library(tidyverse)
install.packages("tidyverse")
library(tidyverse)
library(readxl)
library(aws.s3)
library(aws.ec2metadata)
library(jsonlite)
Sys.setenv("AWS_DEFAULT_REGION" = 'us-west-2')
# Load the JSON file
json_data <- fromJSON(txt = "~/rtdatasci_github/R/aws/aws_key.json")
# Retrieve the AWS key values
key <- json_data$AWS_ACCESS_KEY_ID
secret <- json_data$AWS_SECRET_ACCESS_KEY
Sys.setenv("AWS_ACCESS_KEY_ID" = key,
"AWS_SECRET_ACCESS_KEY" = secret)
# Load the JSON file
json_data <- fromJSON(txt = "~/rtdatasci_github/R/aws/aws_key.json")
Sys.setenv("AWS_ACCESS_KEY_ID" = json_data$AWS_ACCESS_KEY_ID,
"AWS_SECRET_ACCESS_KEY" = json_data$AWS_SECRET_ACCESS_KEY)
# This returns a list of all your buckets if authentication was successful
#cupofaws
bucketlist()
# get the list of files from a bucket
file_list <- aws.s3::get_bucket("s3://cupofaws/")  # s3 object lists
file_df <- aws.s3::get_bucket_df("s3://cupofaws/")  # s3 object dataframe
all_files <- file_df$Key
myfile <- s3read_using(FUN = read_excel, object = "test.xlsx", bucket = "cupofaws")
all_files
s3read_using(FUN = read_excel, object = "test.xlsx", bucket = "cupofaws")
myfile <- s3read_using(FUN = read_excel, object = "s3://cupofaws/test.xlsx")
myfile_mod <- myfile %>% mutate(new_col = ifelse(str_detect(col2, "[a-z]"), "alphanumeric", "numeric"))
myfile_mod
myfile <- s3read_using(FUN = read_excel, object = "test.xlsx", bucket = "cupofaws")
install.packages("paws")
s3 <- paws::s3
s3$list_objects(Bucket = "s3://cupofaws/")
s3
s3_download <- s3$get_object(Bucket = "s3://cupofaws/",
Key = "test.xlsx")
library(magittr)
install.packages(magittr)
install.packages('magittr')
s3 <- paws::s3
s3$list_objects(Bucket = "s3://cupofaws/")
## METHOD 1 :
library(jsonlite)
s3path <- "s3://cupofaws/test.xlsx"
content <- aws.s3::get_object(bucket="s3://cupofaws/", key="test.xlsx")
content <- aws.s3::get_object(object = s3path, key="test.xlsx")
content
content %>% rawToChar %>% read_excel(text =.)
s3path <- "s3://cupofaws/test_mod.csv"
content <- aws.s3::get_object(object = s3path, key="test_mod.csv")
df <- read.csv(text = content, encoding = "UTF-8")
content
content <- aws.s3::get_object(object = "test_mod.csv", bucket="s3://cupofaws/")
df <- read.csv(text = content, encoding = "UTF-8")
content
content <- aws.s3::get_object(object = "s3://cupofaws/test_mod.csv", bucket="s3://cupofaws/")
df <- read.csv(text = content, encoding = "UTF-8")
df <- read.csv(content, encoding = "UTF-8")
library(tidyverse)
library(tidyverse)
install.packages("remotes")
remotes::install_version("rlang", version = "1.1.0")
library(tidyverse)
remove.packages(tidyverse)
remove.packages('tidyverse')
remove.packages('rlang')
remove.packages('ggplot2')
library(ggplot2)
install.packages("tidyverse")
install.packages("tidyverse")
install.packages("tidyverse")
install.packages("tidyverse")
install.packages("tidyverse")
install.packages("tidyverse")
install.packages("tidyverse")
install.packages("tidyverse")
install.packages("tidyverse")
library(tidyverse)
library(readxl)
library(aws.s3)
library(aws.ec2metadata)
library(jsonlite)
Sys.setenv("AWS_DEFAULT_REGION" = 'us-west-2')
# Load the JSON file
json_data <- fromJSON(txt = "~/rtdatasci_github/R/aws/aws_key.json")
# assign the key and secret
Sys.setenv("AWS_ACCESS_KEY_ID" = json_data$AWS_ACCESS_KEY_ID,
"AWS_SECRET_ACCESS_KEY" = json_data$AWS_SECRET_ACCESS_KEY)
# This returns a list of all your buckets if authentication was successful
#cupofaws
bucketlist()
# get the list of files from a bucket
file_list <- aws.s3::get_bucket("s3://cupofaws/")  # s3 object lists
file_df <- aws.s3::get_bucket_df("s3://cupofaws/")  # s3 object dataframe
all_files <- file_df$Key
all_files
## METHOD 1:
# read file from the bucket
myfile <- s3read_using(FUN = read_excel, object = "test.xlsx", bucket = "cupofaws")
myfile <- s3read_using(FUN = read_excel, object = "s3://cupofaws/test.xlsx")
head(myfile)
# write file into the bucket
myfile_mod <- myfile %>% mutate(new_col = ifelse(str_detect(col2, "[a-z]"), "alphanumeric", "numeric"))
myfile_mod
## METHOD 2:
# get content and read csv
content <- aws.s3::get_object(object = "s3://cupofaws/test_mod.csv", bucket="s3://cupofaws/")
content
# convert the alphnumeric content to readable format
df <- read.csv(content, encoding = "UTF-8")
# convert the alphnumeric content to readable format
content %>% rawToChar %>% read.csv(text = .)
# OR
new_content <- content
# OR
new_content <- aws.s3::get_object("s3://cupofaws/test_mod.csv")
read.csv(new_content, encoding = "UTF-8")
# OR
new_content <- aws.s3::get_object("s3://cupofaws/test_mod.csv", bucket="s3://cupofaws")
read.csv(new_content, encoding = "UTF-8")
# OR
new_content <- aws.s3::get_object("s3://cupofaws/test_mod.csv", bucket="cupofaws")
read.csv(new_content, encoding = "UTF-8")
# OR
new_content <- aws.s3::get_object("s3://cupofaws/test_mod.csv")$Body$read()
# OR
new_content <- aws.s3::get_object("s3://cupofaws/test_mod.csv")
new_content$Body$read()
new_content
# OR
new_content <- aws.s3::get_object("s3://cupofaws/test_mod.csv", as.raw())
df <- read_csv("~/rtdatasci_github/R/chatgpt_nlp/chatgpt-reddit-comments.csv", col_types = cols(.default = "c"))
library(tidyverse)
library(dplyr)
library(readr)
library(readxl)
df <- read_csv("~/rtdatasci_github/R/chatgpt_nlp/chatgpt-reddit-comments.csv", col_types = cols(.default = "c"))
View(df)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
library(readr)
library(readxl)
library(tm)
library(tidytext)
library(SnowballC)
df <- read_csv("~/rtdatasci_github/R/chatgpt_nlp/chatgpt-reddit-comments.csv", col_types = cols(.default = "c"))
head(df)
# Split the text_column into sentences
df %>%
unnest_tokens(output = "sentences", input = text_column, token = "sentences") %>%
# Count sentences, per comment
count(comment_body)
df %>%
unnest_tokens(output = "sentences", input = comment_body, token = "sentences")
# Split the text_column into sentences
df %>%
unnest_tokens(output = "sentences", input = comment_body, token = "sentences") %>%
# Count sentences, per chapter
count(sentences)
library(shiny)
library(shiny)
library(haven)   # Read sas
library(ggplot2) # viz
library(scales)
install.packages("shiny")
library(shiny)
library(bslib)
library(plotly)
# Read in Data -------------------------------
adsl <- read_xpt("adsl.xpt")
setwd("~/rtdatasci_github/R/adam_clinical")
# Read in Data -------------------------------
adsl <- read_xpt("adsl.xpt")
View(adsl)
gc()
reticulate::repl_python()
num = [1,3,4,6,8,434,545, 8,3]
Y
num=[1,2,3,4,5,6]
num
num[3:]
num[0:3]+num[4:]
num = [1,3,4,6,8,434,545, 8,3]
rajeev=num[3:]
juno=num[0:3]+num[4:]
juno
quit
gc()
gc()
remove.packages(shiny)
library(shiny)
install.packages('htmltools')
library(shiny)
?htmltoos
?htmltools
install.packages("htmltools")
packageVersion("htmltools")
packageVersion("shiny")
library(devtools)
install.packages("devtools")
library(devtools)
install_version("htmltools", version = "0.5.4")
devtools::install_version("htmltools", version = "0.5.4")
